# Credits:
## Disclaimer for pretrained models:
All rights to the pretrained models used in this project belong to their authors. \
I do not vouch for their quality and do not claim to be licensed to use any model. \
It is your responsibility to determine if you have permission to use the pretrained model under the license for the dataset it was trained on or licensed under. \
Any use of the pretrained model is strictly regulated by the licenses under which the model is distributed. \
If you own the model and want to update it (file, segmentation quality information, etc.) or don't want your model to be included in this tool, please get in touch through a GitHub issue.

## Photos:
The photos in the `docs/imgs/input/` and `docs/code_examples/python/input/` folders were taken from the Pexels website. \
The original photos in the `docs/imgs/compare` folder were taken from the Unsplash site. \
All images are copyrighted by their authors.

## References:
1. https://pytorch.org/hub/pytorch_vision_deeplabv3_resnet101/
2. https://github.com/NathanUA/U-2-Net
3. https://github.com/NathanUA/BASNet
4. https://github.com/MarcoForte/FBA_Matting
5. https://arxiv.org/abs/1706.05587
6. https://arxiv.org/pdf/2005.09007.pdf
7. http://openaccess.thecvf.com/content_CVPR_2019/html/Qin_BASNet_Boundary-Aware_Salient_Object_Detection_CVPR_2019_paper.html
8. https://arxiv.org/abs/2003.07711
9. https://arxiv.org/abs/1506.01497
10. https://arxiv.org/abs/1703.06870
11. https://github.com/Karel911/TRACER
12. https://arxiv.org/abs/2112.07380
